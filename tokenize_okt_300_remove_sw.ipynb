{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "from konlpy.tag import Okt\n",
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('ratings_train.txt','r',encoding='utf-8')\n",
    "rdr = csv.reader(f, delimiter='\\t')\n",
    "rdw = list(rdr)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "okt = Okt()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 불용어 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_df = pd.read_excel('stopwords.xlsx')\n",
    "stopwords_list = stopwords_df['불용어'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for line in rdw:\n",
    "    token_list = okt.pos(line[1],norm=True, stem=True)  #norm은 정규화, stem은 근어\n",
    "    tmp = []\n",
    "    for word in token_list:\n",
    "        if not word[1] in (['Josa','Eomi','Punctuation'],stopwords_list):\n",
    "            tmp.append(word[0])\n",
    "    rl = (' '.join(tmp)).strip()\n",
    "    result.append(rl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('naver_movie.okt','w',encoding='utf-8') as fp:\n",
    "    fp.write('\\n'.join(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "wData = word2vec.LineSentence('naver_movie.okt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "wModel = word2vec.Word2Vec(wData, size=300, window=10, hs=1, min_count=2,sg=1)\n",
    "wModel.save('NaverMovie_okt_wo_sw.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = word2vec.Word2Vec.load('NaverMovie_okt_wo_sw.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('꼽는', 0.6514273285865784), ('꼽을', 0.6169966459274292), ('으뜸', 0.5976998805999756), ('단연', 0.5967167615890503), ('상반기', 0.5936921834945679), ('역사드라마', 0.5870316028594971), ('!!!~', 0.5839056372642517), ('최고다', 0.5832944512367249), ('가금', 0.5800917148590088), ('그렘린', 0.5764350295066833)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-4a2bd6f98709>:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  print(model.most_similar(positive=['최고']))\n"
     ]
    }
   ],
   "source": [
    "print(model.most_similar(positive=['최고']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
